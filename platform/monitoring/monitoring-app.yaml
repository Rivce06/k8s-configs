# NOTE (SRE Best Practices): For production, 'storageSpec' must be configured 
# with a PersistentVolumeClaim (e.g., pd-balanced) and 15d+ retention.
# Current config is optimized for ephemeral lab costs.
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring-stack
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "1"
spec:
  project: default
  source:
    repoURL: "https://prometheus-community.github.io/helm-charts"
    chart: kube-prometheus-stack
    targetRevision: 81.5.0
    helm:
      values: |
        alertmanager:
          enabled: true
          alertmanagerSpec:
            replicas: 1
            resources:
              requests:
                cpu: 50m
                memory: 64Mi
              limits:
                cpu: 200m
                memory: 128Mi
            storage: {}

        grafana:
          enabled: true
          resources:
            requests:
              cpu: 50m
              memory: 100Mi
            limits:
              cpu: 200m
              memory: 256Mi
          service:
            type: ClusterIP

        prometheus:
          enabled: true
          service:
            type: ClusterIP
          prometheusSpec:
            retention: 2h
            storageSpec: {}
            resources:
              requests:
                cpu: "100m"
                memory: "256Mi"
              limits:
                cpu: "500m"
                memory: "1Gi"

        kubeStateMetrics:
          enabled: true

        nodeExporter:
          enabled: false

  destination:
    server: "https://kubernetes.default.svc"
    namespace: monitoring

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
